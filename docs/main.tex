%% Overleaf			
%% Software Manual and Technical Document Template	
%% 									
%% This provides an example of a software manual created in Overleaf.

\documentclass{ol-softwaremanual}

% Packages used in this example
\usepackage{graphicx}  % for including images
\usepackage{microtype} % for typographical enhancements
\usepackage{minted}    % for code listings
\usepackage{amsmath}   % for equations and mathematics
\setminted{style=friendly,fontsize=\small}
\renewcommand{\listoflistingscaption}{List of Code Listings}
\usepackage{hyperref}  % for hyperlinks
\usepackage[a4paper,top=4.2cm,bottom=4.2cm,left=3.5cm,right=3.5cm]{geometry} % 
%for setting page size and margins
\usepackage{csquotes}
\usepackage{nth}

% Custom macros used in this example document
\newcommand{\doclink}[2]{\href{#1}{#2}\footnote{\url{#1}}}
\newcommand{\cs}[1]{\texttt{\textbackslash #1}}
\newcommand{\mmct}{\texttt{mmct}}

% Frontmatter data; appears on title page
\title{MMCT Python Package \\ Documentation}
\version{1.1.2}
\author{Chris Walther Andersen}
%\softwarelogo{\includegraphics[width=8cm]{logo}}

\begin{document}

\maketitle

\section{Introduction}

The purpose of this software is to perform a statistical test on a dataset, in 
order to determine whether the data has been generated from a multinomial 
distribution. The name of the package, \mmct{}, is an abbreviation of 
\enquote{Multinomial Monte Carlo Test}. As the name suggests, the statistical 
test is performed using a Monte Carlo simulation. This document describes the 
mathematical foundations for this task.

The package is inspired by two other software packages, both of which do the 
same job:
The Python-package \doclink{https://pypi.org/project/met/}{met} is also a 
Python-package for performing multinomial tests, however \texttt{met} performs 
an \emph{exact} test. While this strategy is certainly preferred to the Monte 
Carlo version (which will always be an approximate test), an exact test quickly 
becomes infeasible as the problem size grows. The other package to have 
inspired this project is the 
\doclink{https://cran.r-project.org/web/packages/XNomial/vignettes/XNomial.html}{XNomial}
package for the R-programming language. \mmct{} is basically an XNomial-clone 
for 
Python.



\section{Mathematical background}

Assume we have done an experiment in which $N$ observations of a system that 
can end up in one of $k$ different states has been made (e.g. rolling a D6 20 
times: $N=20$, $k=6$). We have tracked the number of times each state occurred 
and denote them $m_1, m_2, \ldots, m_k$, such that $\sum_{i=1}^k m_i = N$.

We want to test the hypothesis that this result is compatible with a 
multinomial distribution with parameters $N$ and $p_1, p_2, \ldots, p_k$, where 
$p_i$ is the probability of the state $i$ occurring and $\sum_{i=1}^k p_i = 
1$. The result of this test should be a p-value for the null hypothesis that 
$m_1, \ldots, m_k$ are drawn from this multinomial distribution.

\subsection{Monte Carlo sampling}

The test is performed in two steps: Monte Carlo sampling a bunch of 
multinomially distributed sets of data, and afterwards determining the 
likelihood of the original dataset occuring based on the sampled data.

First we write the original data under test as
\begin{equation}
X = \left\{ m_1, m_2, \ldots , m_k \right\},
\end{equation}
where $m_i$ is the number of observations in bin $i$. We note that the 
probability observing $X$ given the hypothesised parameters of the distribution 
is
\begin{align}
P &= \Pr\left(m_1, \ldots, m_k | N , p_1, \ldots, p_k\right) \nonumber \\
&= \frac{N!}{m_1! \cdots m_k!} p_1^{m_1} \cdots p_k^{m_k}.
\end{align}

We now draw $N_S$ random samples from the hypothesised distribution, i.e.
\begin{equation}
X^j = \left\{ m_1^j, m_2^j, \ldots, m_k^j \right\},\quad 1\leq j \leq N_S.
\end{equation}
Each sample has been drawn with the probabilities of the hypothesised 
distribution $p_i, 1\leq i\leq k$ and for each sample $\sum_i m_i^j = N$.
If $N_S$ is large enough, we can now estimate the likelihood that $X$ (the data 
under test) is drawn 
from the same distribution by comparing it to the randomly generated samples.

\subsection{Sample grading}

To do this we need a way of grading our samples to determine what is likely and 
what is unlikely. To do this we grade each sample by its 
probability of occurring according to the probability distribution. This 
probability is calculated as
\begin{align}
P^j &= \Pr\left(m^j_1, \ldots, m^j_k | N , p_1, \ldots, p_k\right) \nonumber \\ 
\label{eq:prob}
&= \frac{N!}{m^j_1! \cdots m^j_k!} p_1^{m^j_1} \cdots p_k^{m^j_k}.
\end{align}
Calculating $P$ for all samples and our data under test in this way, we can 
now rank all the samples from the most likely (largest $P^j$) to most unlikely 
(smallest $P^j$) and look where $P$, the probability of the data under test, 
fits 
in. 
The p-value of our test is simply the number of samples with a probability 
$P^j$ smaller than $P$ divided by the total number of samples $N_S$:
\begin{equation}
\textrm{p-value} = \frac{N_{\textrm{smaller}}}{N_S}.
\end{equation}




\end{document}
